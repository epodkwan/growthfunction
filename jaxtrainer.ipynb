{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epodkwan/growthfunction/blob/main/jaxtrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgZPjwP-NEwE",
        "outputId": "cf63e9d4-53d8-4a27-81f6-7051cf6c91c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flax\n",
            "  Downloading flax-0.5.3-py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from flax) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.21.6)\n",
            "Collecting rich~=11.1\n",
            "  Downloading rich-11.2.0-py3-none-any.whl (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 30.4 MB/s \n",
            "\u001b[?25hCollecting tensorstore\n",
            "  Downloading tensorstore-0.1.21-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flax) (0.3.14)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.2->flax) (0.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.2->flax) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.2->flax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.2->flax) (1.7.3)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich~=11.1->flax) (2.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.2->flax) (5.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.2->flax) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax) (1.15.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.3.14+cuda11.cudnn805)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.3-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 351 kB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (2.0)\n",
            "Installing collected packages: commonmark, colorama, chex, tensorstore, rich, PyYAML, optax, flax\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 chex-0.1.3 colorama-0.4.5 commonmark-0.9.1 flax-0.5.3 optax-0.1.3 rich-11.2.0 tensorstore-0.1.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "GXP7APTktM23"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "import jax\n",
        "import optax\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import jit,random\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state,checkpoints\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "Wsb6hTLBtacv"
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    features:Sequence[int]\n",
        "    training:bool\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self,inputs):\n",
        "        x=inputs\n",
        "        for i,feat in enumerate(self.features):\n",
        "            x=nn.Dense(feat)(x)\n",
        "            if i != len(self.features)-1:\n",
        "                x=nn.relu(x)\n",
        "                x=nn.Dropout(rate=0.5)(x,deterministic=not self.training)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "wQ0f5JoEteu2"
      },
      "outputs": [],
      "source": [
        "layer_sizes=[64,256,256,256]\n",
        "learning_rate=1e-6\n",
        "epochs=500000\n",
        "model=SimpleMLP(features=layer_sizes,training=True)\n",
        "temp=jnp.ones(2)\n",
        "key0,key1,key2=random.split(random.PRNGKey(0),3)\n",
        "params=model.init({'params':key0,'dropout':key1},temp)\n",
        "tx=optax.adam(learning_rate=learning_rate,b1=0.9,b2=0.999)\n",
        "opt_state=tx.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "seVyHnrBtU9a"
      },
      "outputs": [],
      "source": [
        "def npy_loader(path):\n",
        "    return jnp.load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "Q4ETnEgYtiz4"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def mse_loss(params,x,y_ref):\n",
        "    preds=model.apply(params,x,rngs={'dropout':key2})\n",
        "    diff=preds-y_ref\n",
        "    return jnp.mean(diff*diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "5KYoOW_TtkmZ"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def train_step(params,opt_state,x,y_ref):\n",
        "    loss,grads=jax.value_and_grad(mse_loss,argnums=0)(params,x,y_ref)\n",
        "    updates,opt_state=tx.update(grads,opt_state)\n",
        "    params=optax.apply_updates(params,updates)\n",
        "    return loss,params,opt_state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def epoch_step(x_train,y_train,params,opt_state,order):\n",
        "    order=random.permutation(random.PRNGKey(i),order)\n",
        "    train_loss=0\n",
        "    for j in range(25):\n",
        "        x_batch=x_train[order[32*j:32*(j+1)-1],:]\n",
        "        y_batch=y_train[order[32*j:32*(j+1)-1],:]\n",
        "        loss,params,opt_state=train_step(params,opt_state,x_batch,y_batch)\n",
        "        train_loss=train_loss+loss\n",
        "    return train_loss,params"
      ],
      "metadata": {
        "id": "w5SOhOLwaCFU"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kspaBRb5xVKq",
        "outputId": "940afee8-e92d-49fc-cc0c-85e6a042875b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "uaH8AxCAtXHD"
      },
      "outputs": [],
      "source": [
        "input_data=npy_loader(\"/content/drive/My Drive/Colab Notebooks/cosmo.npy\")\n",
        "input_result=npy_loader(\"/content/drive/My Drive/Colab Notebooks/combined.npy\")\n",
        "x_train=jnp.stack((input_data[0:800,0],input_data[0:800,2]),axis=1)\n",
        "y_train=input_result[0:800,:]\n",
        "x_validate=jnp.stack((input_data[800:900,0],input_data[800:900,2]),axis=1)\n",
        "y_validate=input_result[800:900,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XBEEkIgktmtw",
        "outputId": "7414841e-e2cb-4c9b-9be0-9e514c69a286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 0.28290814\n",
            "200 0.20299067\n",
            "300 0.16473104\n",
            "400 0.14675663\n",
            "500 0.13792044\n",
            "600 0.13255185\n",
            "700 0.12865578\n",
            "800 0.12552823\n",
            "900 0.12295968\n",
            "1000 0.12089588\n",
            "1100 0.119201206\n",
            "1200 0.117800616\n",
            "1300 0.11667215\n",
            "1400 0.11579391\n",
            "1500 0.115087986\n",
            "1600 0.114528894\n",
            "1700 0.11410738\n",
            "1800 0.11379095\n",
            "1900 0.11356514\n",
            "2000 0.11339986\n",
            "2100 0.11327701\n",
            "2200 0.11318912\n",
            "2300 0.113140926\n",
            "2400 0.113133565\n",
            "2500 0.11315395\n",
            "2600 0.11319727\n",
            "2700 0.11322369\n",
            "2800 0.1132649\n",
            "2900 0.11332986\n",
            "3000 0.11341389\n",
            "3100 0.11351232\n",
            "3200 0.113627695\n",
            "3300 0.11377134\n",
            "3400 0.113923796\n",
            "3500 0.11409676\n",
            "3600 0.11429063\n",
            "3700 0.11449464\n",
            "3800 0.11470968\n",
            "3900 0.11493761\n",
            "4000 0.11517799\n",
            "4100 0.115436435\n",
            "4200 0.11571559\n",
            "4300 0.115995474\n",
            "4400 0.11628428\n",
            "4500 0.11659016\n",
            "4600 0.11692347\n",
            "4700 0.1172777\n",
            "4800 0.11764343\n",
            "4900 0.118019275\n",
            "5000 0.11842163\n",
            "5100 0.11881968\n",
            "5200 0.119227216\n",
            "5300 0.119650304\n",
            "5400 0.120092444\n",
            "5500 0.12055033\n",
            "5600 0.1210149\n",
            "5700 0.12149675\n",
            "5800 0.121999115\n",
            "5900 0.12251837\n",
            "6000 0.12306316\n",
            "6100 0.12363905\n",
            "6200 0.124233246\n",
            "6300 0.12485041\n",
            "6400 0.1254872\n",
            "6500 0.12615398\n",
            "6600 0.12681569\n",
            "6700 0.1274868\n",
            "6800 0.12819028\n",
            "6900 0.12892371\n",
            "7000 0.12967227\n",
            "7100 0.13045065\n",
            "7200 0.1312234\n",
            "7300 0.13200377\n",
            "7400 0.13279311\n",
            "7500 0.133566\n",
            "7600 0.13435149\n",
            "7700 0.13514717\n",
            "7800 0.13594449\n",
            "7900 0.13673861\n",
            "8000 0.13754316\n",
            "8100 0.13837671\n",
            "8200 0.13922468\n",
            "8300 0.1400649\n",
            "8400 0.14091328\n",
            "8500 0.14176226\n",
            "8600 0.1426056\n",
            "8700 0.14344147\n",
            "8800 0.14427531\n",
            "8900 0.14508612\n",
            "9000 0.14589037\n",
            "9100 0.14664868\n",
            "9200 0.14739579\n",
            "9300 0.14808218\n",
            "9400 0.14875177\n",
            "9500 0.14939417\n",
            "9600 0.14997995\n",
            "9700 0.15053993\n",
            "9800 0.15107547\n",
            "9900 0.15158306\n",
            "10000 0.15207955\n",
            "10100 0.15256236\n",
            "10200 0.1530215\n",
            "10300 0.15344699\n",
            "10400 0.15384099\n",
            "10500 0.15422775\n",
            "10600 0.15461935\n",
            "10700 0.15500377\n",
            "10800 0.1553856\n",
            "10900 0.15575327\n",
            "11000 0.15611002\n",
            "11100 0.15646169\n",
            "11200 0.15682212\n",
            "11300 0.15716484\n",
            "11400 0.15749592\n",
            "11500 0.15782836\n",
            "11600 0.15816784\n",
            "11700 0.15849937\n",
            "11800 0.15882151\n",
            "11900 0.15914944\n",
            "12000 0.1594849\n",
            "12100 0.15980025\n",
            "12200 0.16011707\n",
            "12300 0.16043696\n",
            "12400 0.16076152\n",
            "12500 0.16109224\n",
            "12600 0.1614192\n",
            "12700 0.16174285\n",
            "12800 0.16206314\n",
            "12900 0.16238014\n",
            "13000 0.16270222\n",
            "13100 0.16303293\n",
            "13200 0.16335769\n",
            "13300 0.1636736\n",
            "13400 0.16397293\n",
            "13500 0.16425857\n",
            "13600 0.1645375\n",
            "13700 0.16479945\n",
            "13800 0.16505003\n",
            "13900 0.16530918\n",
            "14000 0.16558501\n",
            "14100 0.16586182\n",
            "14200 0.16612045\n",
            "14300 0.16636223\n",
            "14400 0.16660918\n",
            "14500 0.16686188\n",
            "14600 0.16712832\n",
            "14700 0.16740215\n",
            "14800 0.1676597\n",
            "14900 0.16792229\n",
            "15000 0.16818267\n",
            "15100 0.16845024\n",
            "15200 0.16871962\n",
            "15300 0.16899104\n",
            "15400 0.16925411\n",
            "15500 0.16950557\n",
            "15600 0.16975337\n",
            "15700 0.16999443\n",
            "15800 0.17024036\n",
            "15900 0.1704917\n",
            "16000 0.1707344\n",
            "16100 0.17097795\n",
            "16200 0.17122272\n",
            "16300 0.17145549\n",
            "16400 0.17168327\n",
            "16500 0.1719122\n",
            "16600 0.17214021\n",
            "16700 0.1723603\n",
            "16800 0.17257042\n",
            "16900 0.17277855\n",
            "17000 0.17298007\n",
            "17100 0.17317909\n",
            "17200 0.1733728\n",
            "17300 0.1735675\n",
            "17400 0.17376097\n",
            "17500 0.17395517\n",
            "17600 0.17414416\n",
            "17700 0.17433582\n",
            "17800 0.1745305\n",
            "17900 0.17472263\n",
            "18000 0.17489973\n",
            "18100 0.17507789\n",
            "18200 0.17525117\n",
            "18300 0.17542267\n",
            "18400 0.1755994\n",
            "18500 0.17577493\n",
            "18600 0.17593482\n",
            "18700 0.17609745\n",
            "18800 0.17626244\n",
            "18900 0.17644943\n",
            "19000 0.17664\n",
            "19100 0.17682575\n",
            "19200 0.1770233\n",
            "19300 0.17721762\n",
            "19400 0.17740749\n",
            "19500 0.17760582\n",
            "19600 0.17779256\n",
            "19700 0.17798488\n",
            "19800 0.17816798\n",
            "19900 0.17834364\n",
            "20000 0.17850666\n",
            "20100 0.17866258\n",
            "20200 0.17880294\n",
            "20300 0.1789339\n",
            "20400 0.179056\n",
            "20500 0.17918064\n",
            "20600 0.17930324\n",
            "20700 0.17942408\n",
            "20800 0.17953256\n",
            "20900 0.17964482\n",
            "21000 0.1797493\n",
            "21100 0.17984834\n",
            "21200 0.17994331\n",
            "21300 0.1800502\n",
            "21400 0.18015006\n",
            "21500 0.18024978\n",
            "21600 0.18035068\n",
            "21700 0.18044543\n",
            "21800 0.18054886\n",
            "21900 0.18065792\n",
            "22000 0.18077114\n",
            "22100 0.18088436\n",
            "22200 0.18099254\n",
            "22300 0.18109283\n",
            "22400 0.18120213\n",
            "22500 0.18132626\n",
            "22600 0.18145676\n",
            "22700 0.18158299\n",
            "22800 0.18171199\n",
            "22900 0.18184868\n",
            "23000 0.18198974\n",
            "23100 0.18211956\n",
            "23200 0.18223937\n",
            "23300 0.18235417\n",
            "23400 0.18246432\n",
            "23500 0.1825676\n",
            "23600 0.18266721\n",
            "23700 0.18276657\n",
            "23800 0.18285884\n",
            "23900 0.18296906\n",
            "24000 0.18308279\n",
            "24100 0.183189\n",
            "24200 0.18328725\n",
            "24300 0.18338089\n",
            "24400 0.18347426\n",
            "24500 0.18357062\n",
            "24600 0.18365754\n",
            "24700 0.18373947\n",
            "24800 0.18382387\n",
            "24900 0.18390526\n",
            "25000 0.18398482\n",
            "25100 0.18406188\n",
            "25200 0.18414061\n",
            "25300 0.18422838\n",
            "25400 0.18432774\n",
            "25500 0.18442371\n",
            "25600 0.18451767\n",
            "25700 0.18461108\n",
            "25800 0.1847044\n",
            "25900 0.1847956\n",
            "26000 0.1848834\n",
            "26100 0.18496516\n",
            "26200 0.18506789\n",
            "26300 0.18516506\n",
            "26400 0.18526226\n",
            "26500 0.18536943\n",
            "26600 0.18547161\n",
            "26700 0.18557575\n",
            "26800 0.18568455\n",
            "26900 0.18579462\n",
            "27000 0.18590765\n",
            "27100 0.1860291\n",
            "27200 0.18615097\n",
            "27300 0.18628123\n",
            "27400 0.18640906\n",
            "27500 0.186541\n",
            "27600 0.1866783\n",
            "27700 0.18681158\n",
            "27800 0.18695374\n",
            "27900 0.18711199\n",
            "28000 0.18727821\n",
            "28100 0.18743604\n",
            "28200 0.18759006\n",
            "28300 0.18773705\n",
            "28400 0.18786566\n",
            "28500 0.1879855\n",
            "28600 0.1881015\n",
            "28700 0.18821616\n",
            "28800 0.18832278\n",
            "28900 0.188428\n",
            "29000 0.18853395\n",
            "29100 0.18863326\n",
            "29200 0.1887322\n",
            "29300 0.18884328\n",
            "29400 0.18895626\n",
            "29500 0.18907697\n",
            "29600 0.18920013\n",
            "29700 0.18932241\n",
            "29800 0.1894412\n",
            "29900 0.1895642\n",
            "30000 0.18967873\n",
            "30100 0.18978691\n",
            "30200 0.18988863\n",
            "30300 0.18999\n",
            "30400 0.19009566\n",
            "30500 0.19020641\n",
            "30600 0.19031906\n",
            "30700 0.19043572\n",
            "30800 0.19055636\n",
            "30900 0.19067806\n",
            "31000 0.19080006\n",
            "31100 0.19092996\n",
            "31200 0.19107161\n",
            "31300 0.19121648\n",
            "31400 0.1913641\n",
            "31500 0.1915163\n",
            "31600 0.19168344\n",
            "31700 0.19185437\n",
            "31800 0.19203216\n",
            "31900 0.19220917\n",
            "32000 0.19239101\n",
            "32100 0.19258066\n",
            "32200 0.19277914\n",
            "32300 0.19298464\n",
            "32400 0.19318679\n",
            "32500 0.19339095\n",
            "32600 0.19361266\n",
            "32700 0.19384162\n",
            "32800 0.1940777\n",
            "32900 0.1943276\n",
            "33000 0.19456805\n",
            "33100 0.19482364\n",
            "33200 0.1950758\n",
            "33300 0.19533104\n",
            "33400 0.19559486\n",
            "33500 0.19586712\n",
            "33600 0.1961506\n",
            "33700 0.19644172\n",
            "33800 0.19673847\n",
            "33900 0.19703889\n",
            "34000 0.19733484\n",
            "34100 0.19763839\n",
            "34200 0.1979422\n",
            "34300 0.1982446\n",
            "34400 0.19854863\n",
            "34500 0.1988535\n",
            "34600 0.19916378\n",
            "34700 0.19947208\n",
            "34800 0.19977164\n",
            "34900 0.20007053\n",
            "35000 0.20036842\n",
            "35100 0.20068595\n",
            "35200 0.20100792\n",
            "35300 0.20132238\n",
            "35400 0.20163424\n",
            "35500 0.20193592\n",
            "35600 0.20223567\n",
            "35700 0.20253284\n",
            "35800 0.2028289\n",
            "35900 0.2031274\n",
            "36000 0.20342605\n",
            "36100 0.20373482\n",
            "36200 0.20404598\n",
            "36300 0.20435062\n",
            "36400 0.20466262\n",
            "36500 0.20497887\n",
            "36600 0.20529678\n",
            "36700 0.20561406\n",
            "36800 0.20593902\n",
            "36900 0.20623936\n",
            "37000 0.20652126\n",
            "37100 0.20681389\n",
            "37200 0.20710754\n",
            "37300 0.20740491\n",
            "37400 0.20770447\n",
            "37500 0.20800497\n",
            "37600 0.20831214\n",
            "37700 0.20862328\n",
            "37800 0.2089369\n",
            "37900 0.20925662\n",
            "38000 0.20957527\n",
            "38100 0.20989788\n",
            "38200 0.21022415\n",
            "38300 0.21055505\n",
            "38400 0.21089521\n",
            "38500 0.21124107\n",
            "38600 0.21157782\n",
            "38700 0.21191259\n",
            "38800 0.21224673\n",
            "38900 0.21257724\n",
            "39000 0.2129021\n",
            "39100 0.21323565\n",
            "39200 0.21357363\n",
            "39300 0.21391807\n",
            "39400 0.21426167\n",
            "39500 0.21459477\n",
            "39600 0.21492134\n",
            "39700 0.21523927\n",
            "39800 0.21554327\n",
            "39900 0.21583563\n",
            "40000 0.21612953\n",
            "40100 0.2164307\n",
            "40200 0.21673281\n",
            "40300 0.2170413\n",
            "40400 0.21734886\n",
            "40500 0.21766615\n",
            "40600 0.21797432\n",
            "40700 0.2182703\n",
            "40800 0.21856421\n",
            "40900 0.21885525\n",
            "41000 0.21914245\n",
            "41100 0.2194266\n",
            "41200 0.21971329\n",
            "41300 0.21998747\n",
            "41400 0.22025245\n",
            "41500 0.22051734\n",
            "41600 0.22077441\n",
            "41700 0.22102718\n",
            "41800 0.2212836\n",
            "41900 0.22153933\n",
            "42000 0.22179648\n",
            "42100 0.22204353\n",
            "42200 0.22229344\n",
            "42300 0.22254947\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-05d5aeeb1347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/frozen_dict.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(cls, _, data)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# data is already deep copied due to tree map mechanism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "order=jnp.arange(800)\n",
        "for i in range(epochs):\n",
        "    train_loss,params=epoch_step(x_train,y_train,params,opt_state,order)\n",
        "    if i % 100 == 99:\n",
        "        train_loss=train_loss/25\n",
        "        validate_loss=mse_loss(params,x_validate,y_validate)\n",
        "        print((i+1),validate_loss)\n",
        "        plt.scatter((i+1),jnp.log(train_loss),c='b')\n",
        "        plt.scatter((i+1),jnp.log(validate_loss),c='g')\n",
        "print(\"Training ended\")\n",
        "state=train_state.TrainState.create(apply_fn=model.apply,params=params,tx=tx)\n",
        "checkpoints.save_checkpoint(ckpt_dir=\"/content/drive/My Drive/Colab Notebooks\",target=state,step=0,overwrite=True)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"ln(loss)\")\n",
        "plt.title(\"Loss function\")\n",
        "plt.legend([\"Training Loss\",\"Validation Loss\"])\n",
        "plt.savefig(\"/content/drive/My Drive/Colab Notebooks/loss.png\")\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4lHuAF6tpcK"
      },
      "outputs": [],
      "source": [
        "x_test=jnp.stack((input_data[900:1000,0],input_data[900:1000,2]),axis=1)\n",
        "y_test=input_result[900:1000,:]\n",
        "model_eval=SimpleMLP(features=layer_sizes,training=False)\n",
        "y_pred=model_eval.apply(params,x_test)\n",
        "print(y_pred)\n",
        "error=abs(y_pred/y_test-1)\n",
        "print(\"Max error =\",jnp.max(error)*100,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qJ5kCMiTs77t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "jaxtrainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrQzRzun/QSqHLWaamBGEj",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}