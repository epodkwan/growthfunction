{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epodkwan/growthfunction/blob/main/notebooks/bsplinetrainer_normalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgZPjwP-NEwE",
        "outputId": "098f2946-ff1a-4f1b-b67b-3b6b58123a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flax\n",
            "  Downloading flax-0.6.0-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from flax) (6.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from flax) (4.1.1)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.7/dist-packages (from flax) (0.3.17)\n",
            "Collecting rich~=11.1\n",
            "  Downloading rich-11.2.0-py3-none-any.whl (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 67.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (3.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (0.7.1)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (1.7.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (1.2.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich~=11.1->flax) (2.6.1)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.16->flax) (5.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.16->flax) (3.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax) (1.15.0)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.4-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.3.15+cuda11.cudnn805)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.12.0)\n",
            "Installing collected packages: commonmark, colorama, chex, rich, optax, flax\n",
            "Successfully installed chex-0.1.4 colorama-0.4.5 commonmark-0.9.1 flax-0.6.0 optax-0.1.3 rich-11.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXP7APTktM23",
        "outputId": "93a8a9f3-1e93-4683-e9f9-79692e55419c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import sys, os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false'\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/growth/')\n",
        "from conf import Configuration\n",
        "from cosmology import Cosmology, SimpleLCDM, growth_integ\n",
        "from growth_mlp_unnorm import Growth_MLP\n",
        "\n",
        "from typing import Sequence\n",
        "import random\n",
        "import statistics\n",
        "import jax\n",
        "import optax\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, vmap, grad\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state, checkpoints\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "seVyHnrBtU9a"
      },
      "outputs": [],
      "source": [
        "def npy_loader(path):\n",
        "    return jnp.load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wsb6hTLBtacv"
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    features:Sequence[int]\n",
        "    nodes:int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs):\n",
        "        x=inputs\n",
        "        for feat in self.features:\n",
        "            x=nn.Dense(feat)(x)\n",
        "            x=nn.elu(x)\n",
        "        t=nn.Dense(nodes-2)(nn.elu(nn.Dense(64)(x)))\n",
        "        c=nn.Dense(nodes)(nn.elu(nn.Dense(64)(x)))\n",
        "        t=jnp.concatenate([jnp.zeros((t.shape[0], 4)), jnp.cumsum(jax.nn.softmax(t), axis=1), jnp.ones((t.shape[0], 4))], axis=1)\n",
        "        c=jnp.concatenate([jnp.zeros((c.shape[0], 1)), c, jnp.ones((c.shape[0], 1))], axis=1)\n",
        "        return t, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "04vwJv7pMgwz"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def _deBoorVectorized(x, t, c):\n",
        "    p=3\n",
        "    k=jnp.digitize(x, t)-1\n",
        "    d=[c[j+k-p] for j in range(0, p+1)]\n",
        "    for r in range(1, p+1):\n",
        "        for j in range(p, r-1, -1):\n",
        "            alpha=(x-t[j+k-p])/(t[j+1+k-r]-t[j+k-p])\n",
        "            d[j]=(1.0-alpha)*d[j-1]+alpha*d[j]\n",
        "    return d[p]\n",
        "\n",
        "deBoor=vmap(_deBoorVectorized, in_axes=(None, 0, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fGSxL7n_Y6LA"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def eval_func(params, x, a):\n",
        "    t, c=model.apply(params, x)\n",
        "    preds=deBoor(jnp.clip(a, 0, 0.99999), t, c)\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rgmBVdmE_Ztq"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def D(a, cosmo):\n",
        "    conf=cosmo.conf \n",
        "    a=jnp.asarray(a, dtype=conf.cosmo_dtype)\n",
        "    D=a * jnp.interp(a, conf.growth_a, cosmo.growth[0][0])\n",
        "    D1=1 * jnp.interp(1., conf.growth_a, cosmo.growth[0][0])\n",
        "    return D/D1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YfugSlbNL4DQ"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def objective_a(params, conf, a_test):\n",
        "    omegam, omegak, w0, wa=params\n",
        "    cosmo=SimpleLCDM(conf, Omega_m=omegam, Omega_k=omegak, w_0=w0, w_a=wa)\n",
        "    cosmo=growth_integ(cosmo)\n",
        "    obj=D(jnp.asarray(a_test), cosmo)\n",
        "    return obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3OreC_-2L6le"
      },
      "outputs": [],
      "source": [
        "obj_grad_a=jit(grad(objective_a, argnums=(0)))\n",
        "vmap_obj_grad_a=vmap(obj_grad_a, in_axes=(None, None, 0))\n",
        "nc=32\n",
        "cell_size=8\n",
        "growth_anum=512\n",
        "conf=Configuration(cell_size=cell_size, mesh_shape=(nc, )*3, growth_anum=growth_anum)\n",
        "layer_sizes=[64]\n",
        "nodes=8\n",
        "learning_rate=1e-5\n",
        "epochs=50000\n",
        "model=SimpleMLP(features=layer_sizes, nodes=nodes)\n",
        "temp=jnp.array([[1]])\n",
        "params=model.init(jax.random.PRNGKey(0), temp)\n",
        "tx=optax.adam(learning_rate=learning_rate)\n",
        "opt_state=tx.init(params)\n",
        "target=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q4ETnEgYtiz4"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def mse_loss(params, x, y_ref, a):\n",
        "    preds=eval_func(params, x, a)\n",
        "    diff=preds-y_ref\n",
        "    return jnp.mean(diff*diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5KYoOW_TtkmZ"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def train_step(opt_state, params, x, y_ref, a):\n",
        "    loss, grads=jax.value_and_grad(mse_loss, argnums=0)(params, x, y_ref, a)\n",
        "    updates, opt_state=tx.update(grads, opt_state)\n",
        "    params=optax.apply_updates(params, updates)\n",
        "    return loss, params, opt_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w5SOhOLwaCFU"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def epoch_step(x_train, y_train, params, opt_state, order, a):\n",
        "    order=jax.random.permutation(jax.random.PRNGKey(i), order)\n",
        "    train_loss=0\n",
        "    for j in range(25):\n",
        "        x_batch=x_train[order[32*j:32*(j+1)], :]\n",
        "        y_batch=y_train[order[32*j:32*(j+1)], :]\n",
        "        loss, params, opt_state=train_step(opt_state, params, x_batch, y_batch, a)\n",
        "        train_loss=train_loss+loss\n",
        "    return train_loss, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kspaBRb5xVKq",
        "outputId": "5692d015-9e0e-4fcf-9400-3956c971b2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uaH8AxCAtXHD"
      },
      "outputs": [],
      "source": [
        "input_data=npy_loader(\"./lindata\"+str(target)+\"norm/cosmo.npy\")\n",
        "input_result=npy_loader(\"./lindata\"+str(target)+\"norm/combined.npy\")\n",
        "a=npy_loader(\"./lindata\"+str(target)+\"norm/999.npy\")[0, :]\n",
        "# input_result=jnp.log(raw_input_result)\n",
        "x_train=input_data[0:800].reshape(800, -1)\n",
        "y_train=input_result[0:800, :]\n",
        "x_validate=input_data[800:900, 0].reshape(100, -1)\n",
        "y_validate=input_result[800:900, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XBEEkIgktmtw",
        "outputId": "737559e7-ef2f-4f62-d3f9-366fc0d2a7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 0.027025012461612645\n",
            "200 0.0020671999727039695\n",
            "300 0.0001712551198958411\n",
            "400 5.171724906121142e-05\n",
            "500 1.7865651504872592e-05\n",
            "600 7.485829964095404e-06\n",
            "700 4.410862436709005e-06\n",
            "800 3.4015629004437316e-06\n",
            "900 2.824826641835232e-06\n",
            "1000 2.2023672807978413e-06\n",
            "1100 1.6054498451374523e-06\n",
            "1200 1.2177991218867606e-06\n",
            "1300 9.851550116181158e-07\n",
            "1400 8.470234122273066e-07\n",
            "1500 7.564349913522747e-07\n",
            "1600 6.908976811306457e-07\n",
            "1700 6.404367186957439e-07\n",
            "1800 5.991974921940827e-07\n",
            "1900 5.653271719475214e-07\n",
            "2000 5.365427948212752e-07\n",
            "2100 5.10217977476722e-07\n",
            "2200 4.860881105823675e-07\n",
            "2300 4.6500033796231815e-07\n",
            "2400 4.463099170756968e-07\n",
            "2500 4.288044402171696e-07\n",
            "2600 4.1251215931240563e-07\n",
            "2700 3.9536840903649174e-07\n",
            "2800 3.897095910357781e-07\n",
            "2900 3.7194929990550616e-07\n",
            "3000 3.5739349421361617e-07\n",
            "3100 3.549094626484503e-07\n",
            "3200 3.383948783579987e-07\n",
            "3300 3.2675511110251163e-07\n",
            "3400 3.25998704317748e-07\n",
            "3500 3.1699952095593396e-07\n",
            "3600 3.0935734352754425e-07\n",
            "3700 2.979104651222729e-07\n",
            "3800 2.908596867649923e-07\n",
            "3900 2.877316071875398e-07\n",
            "4000 2.7925383512798827e-07\n",
            "4100 2.73510132282334e-07\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d80e141b7b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/frozen_dict.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(cls, _, data)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# data is already deep copied due to tree map mechanism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/fixend/\")\n",
        "order=jnp.arange(800)\n",
        "for i in range(epochs):\n",
        "    train_loss, params=epoch_step(x_train, y_train, params, opt_state, order, a)\n",
        "    if i % 100 == 99:\n",
        "        train_loss=train_loss/25\n",
        "        validate_loss=mse_loss(params, x_validate, y_validate, a)\n",
        "        print((i+1), validate_loss)\n",
        "        plt.scatter((i+1), train_loss, c='b')\n",
        "        plt.scatter((i+1), validate_loss, c='g')\n",
        "print(\"Training ended\")\n",
        "state=train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
        "checkpoints.save_checkpoint(ckpt_dir=(\"./\"+str(target)+\"/\"), target=state, step=0, overwrite=True)\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss function\")\n",
        "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
        "plt.savefig(\"./\"+str(target)+\"loss.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuALbWCBYtRe"
      },
      "outputs": [],
      "source": [
        "params_class={}\n",
        "for order in range(1, 3):\n",
        "    for deriv in range(3):\n",
        "        key=\"{}{}\".format(order, deriv)\n",
        "        params_class[key]=params\n",
        "growth_fn=Growth_MLP(model, params_class)\n",
        "growth_integ_jit=jit(growth_integ)\n",
        "omega_m_test=0.11\n",
        "omega_k_test=0.\n",
        "w_0_test=-1.\n",
        "w_a_test=0.\n",
        "a_test=jnp.linspace(0., 1., 100)\n",
        "epsilon=1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0uvMeFTYdb4"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def predict(cosmo, a):\n",
        "    return growth_fn(cosmo, a).reshape(-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1bCgtCqMUdK"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def gradient_at(cosmo, a):\n",
        "    value1, gradient=jax.value_and_grad(predict, 0)(jnp.array([cosmo]), a)\n",
        "    return value1, gradient\n",
        "\n",
        "vmap_gradient_at=vmap(gradient_at, in_axes=(None, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUbCCT2m6p_q"
      },
      "outputs": [],
      "source": [
        "cosmo_test=SimpleLCDM(conf, Omega_m=omega_m_test, Omega_k=omega_k_test, w_0=w_0_test, w_a=w_a_test)\n",
        "cosmo_test=growth_integ_jit(cosmo_test)\n",
        "d_data=D(a_test, cosmo_test)\n",
        "d_test=growth_fn(jnp.array([[omega_m_test]]), a_test).reshape(-1)\n",
        "discrepancy=(abs(d_test)+epsilon)/(abs(d_data)+epsilon)\n",
        "fig, (ax1, ax2, ax3)=plt.subplots(3, 1, constrained_layout=True)\n",
        "ax1.plot(a_test, d_data, label=\"Reference\")\n",
        "ax1.plot(a_test, d_test, label=\"Fitting\")\n",
        "ax1.set_ylabel(\"D\")\n",
        "ax1.legend()\n",
        "ax1.set_title(\"Value\")\n",
        "ax2.plot(a_test, discrepancy)\n",
        "ax2.set_ylabel(\"Predict/Data\")\n",
        "ax2.ticklabel_format(useOffset=False)\n",
        "ax3.plot(a_test, d_test-d_data)\n",
        "ax3.set_ylabel(\"Difference\")\n",
        "ax3.set_xlabel(\"a\")\n",
        "plt.savefig(\"./\"+str(target)+\"value.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ari-7kNvmP-_"
      },
      "outputs": [],
      "source": [
        "a_plot=[]\n",
        "med=[]\n",
        "mean_error=[]\n",
        "std=[]\n",
        "for i in range(10):\n",
        "    plt.clf()\n",
        "    temp=[]\n",
        "    for j in range(1000):\n",
        "        d_data=input_result[j, i*28]/input_result[j, -1]\n",
        "        d_test=growth_fn(jnp.array([[input_data[j, 0]]]), a[i*28]).reshape(-1)\n",
        "        temp.append(((abs(d_test)+epsilon)/(abs(d_data)+epsilon)-1).item())\n",
        "        plt.scatter(input_data[j, 0], temp[-1], c='b')\n",
        "    plt.xlim(0.1, 0.5)\n",
        "    plt.xlabel(\"Omega_m\")\n",
        "    plt.ylabel(\"Fractional Error\")\n",
        "    plt.title(\"Fractional Error of Cosmos (a=\"+str(np.round(a[i*28].item(), 3))+\")\")\n",
        "    plt.savefig(\"./\"+str(target)+\"error\"+str(i)+\".png\")\n",
        "    a_plot.append(a[i*28].item())\n",
        "    med.append(statistics.median(temp))\n",
        "    mean_error.append(statistics.mean(temp))\n",
        "    std.append(statistics.stdev(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXtPDjF2Hlmx"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "fig, ax=plt.subplots(constrained_layout=True)\n",
        "ax.plot(a_plot, med, label=\"Median\")\n",
        "ax.errorbar(a_plot, mean_error, std, label=\"Mean\")\n",
        "# ax.set_xscale('log')\n",
        "ax.set_xlabel(\"a\")\n",
        "ax.set_ylabel(\"Fractional Error\")\n",
        "ax.set_title(\"Fractional Error\")\n",
        "ax.legend()\n",
        "plt.savefig(\"./\"+str(target)+\"centralerror.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NwZwYE5sT1e"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "cosmo_test=[omega_m_test, omega_k_test, w_0_test, w_a_test]\n",
        "value, grad=vmap_gradient_at([omega_m_test], a_test)\n",
        "grad_test=grad\n",
        "grad_ref=vmap_obj_grad_a(cosmo_test, conf, a_test)[0]\n",
        "grad_ref=np.array(grad_ref).reshape(-1)\n",
        "grad_test=np.array(grad_test).reshape(-1)\n",
        "discrepancy=(abs(grad_test)+epsilon)/(abs(grad_ref)+epsilon)\n",
        "fig, (ax1, ax2, ax3)=plt.subplots(3, 1, constrained_layout=True)\n",
        "ax1.plot(a_test, grad_ref, label=\"Reference\")\n",
        "ax1.plot(a_test, grad_test, label=\"Neural Network\")\n",
        "ax1.legend()\n",
        "ax1.set_title(\"Gradient\")\n",
        "ax2.plot(a_test, discrepancy)\n",
        "ax2.set_ylabel(\"Predict/Data\")\n",
        "ax2.ticklabel_format(useOffset=False)\n",
        "ax3.plot(a_test, grad_test-grad_ref)\n",
        "ax3.set_ylabel(\"Difference\")\n",
        "ax3.set_xlabel(\"a\")\n",
        "plt.savefig(\"./\"+str(target)+\"gradient.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI9LdlimNket"
      },
      "outputs": [],
      "source": [
        "max_error_ref=[]\n",
        "max_error_test=[]\n",
        "max_difference_ref=[]\n",
        "max_difference_test=[]\n",
        "for i in range(1000):\n",
        "    value, grad_test=vmap_gradient_at([input_data[i, 0]], a_test)\n",
        "    grad_ref=vmap_obj_grad_a([input_data[i, 0], omega_k_test, w_0_test, w_a_test], conf, a_test)[0]\n",
        "    grad_ref=np.array(grad_ref).reshape(-1)\n",
        "    grad_test=np.array(grad_test).reshape(-1)\n",
        "    error=abs((abs(grad_test)+epsilon)/(abs(grad_ref)+epsilon)-1)\n",
        "    difference=abs(grad_test-grad_ref)\n",
        "    temp=jnp.where(error==jnp.max(error))\n",
        "    max_error_ref.append(grad_ref[temp])\n",
        "    max_error_test.append(grad_test[temp])\n",
        "    temp=jnp.where(difference==jnp.max(difference))\n",
        "    max_difference_ref.append(grad_ref[temp])\n",
        "    max_difference_test.append(grad_test[temp])\n",
        "max_error_ref=np.array(max_error_ref)\n",
        "max_error_test=np.array(max_error_test)\n",
        "max_difference_ref=np.array(max_difference_ref)\n",
        "max_difference_test=np.array(max_difference_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "fig, (ax1, ax2, ax3)=plt.subplots(3, 1, constrained_layout=True)\n",
        "ax1.scatter(input_data[:, 0], (abs(max_error_test)+epsilon)/(abs(max_error_ref)+epsilon)-1)\n",
        "ax1.set_ylabel(\"Fractional Error\")\n",
        "ax1.set_xlim(0.1, 0.5)\n",
        "# ax1.set_ylim(-10, 20)\n",
        "ax1.set_title(\"Max Error\")\n",
        "ax2.scatter(input_data[:, 0], max_error_test-max_error_ref)\n",
        "ax2.set_ylabel(\"Difference\")\n",
        "ax2.set_xlim(0.1, 0.5)\n",
        "# ax2.set_ylim(-0.05, 0.05)\n",
        "ax3.scatter(input_data[:, 0], max_error_ref)\n",
        "ax3.set_ylabel(\"Gradient\")\n",
        "ax3.set_xlabel(\"Omega_m\")\n",
        "ax3.set_xlim(0.1, 0.5)\n",
        "plt.ticklabel_format(useOffset=False)\n",
        "plt.savefig(\"./\"+str(target)+\"maxerror.png\")"
      ],
      "metadata": {
        "id": "o9qkWMLW9VuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "fig, (ax1, ax2, ax3)=plt.subplots(3, 1, constrained_layout=True)\n",
        "ax1.scatter(input_data[:, 0], max_difference_test-max_difference_ref)\n",
        "ax1.set_ylabel(\"Difference\")\n",
        "ax1.set_xlim(0.1, 0.5)\n",
        "# ax1.set_ylim(-0.05, 0.05)\n",
        "ax1.set_title(\"Max Difference\")\n",
        "ax2.scatter(input_data[:, 0], (abs(max_difference_test)+epsilon)/(abs(max_difference_ref)+epsilon)-1)\n",
        "ax2.set_ylabel(\"Fractional Error\")\n",
        "ax2.set_xlim(0.1, 0.5)\n",
        "# ax2.set_ylim(-10, 20)\n",
        "ax3.scatter(input_data[:, 0], max_error_ref)\n",
        "ax3.set_ylabel(\"Gradient\")\n",
        "ax3.set_xlabel(\"Omega_m\")\n",
        "ax3.set_xlim(0.1, 0.5)\n",
        "plt.ticklabel_format(useOffset=False)\n",
        "plt.savefig(\"./\"+str(target)+\"maxdifference.png\")"
      ],
      "metadata": {
        "id": "YAmPz-nZ9Ydu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3zEr_lc_zWg"
      },
      "outputs": [],
      "source": [
        "# drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1oYejJcAlvCGFIpWJWB1lL9vjbRHJ86u5",
      "authorship_tag": "ABX9TyMtxmERiIi4bmryby0HaVGx",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}